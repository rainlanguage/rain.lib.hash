<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title></title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="book.css">

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item "><a href="index.html">Home</a></li><li class="chapter-item affix "><li class="part-title">src</li><li class="chapter-item "><a href="src/LibHashNoAlloc.sol/library.LibHashNoAlloc.html">LibHashNoAlloc</a></li><li class="chapter-item "><a href="src/LibHashNoAlloc.sol/constants.LibHashNoAlloc.html">LibHashNoAlloc constants</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title"></h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/rainprotocol/rain.lib.hash" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="rainlibhash"><a class="header" href="#rainlibhash">rain.lib.hash</a></h1>
<p>Docs at https://rainprotocol.github.io/rain.lib.hash</p>
<h2 id="problem"><a class="header" href="#problem">Problem</a></h2>
<p>When producing hashes of just about anything that isn't already <code>bytes</code> the
common suggestions look something like <code>keccak256(abi.encode(...))</code> or
<code>keccak256(abi.encodePacked(...))</code>. This appears reasonable as Solidity itself
does not provide an &quot;any type&quot; <code>keccak256</code> function but does provide one (almost)
for abi encoding.</p>
<p>When I say &quot;common suggestion&quot; I mean literally the compiler itself gives outputs
like this for any type other than <code>bytes</code>.</p>
<pre><code>‚ûú keccak256(address(0))
Compiler errors:
error[7556]: TypeError: Invalid type for argument in function call. Invalid implicit conversion from address to bytes memory requested. This function requires a single bytes argument. Use abi.encodePacked(...) to obtain the pre-0.5.0 behaviour or abi.encode(...) to use ABI encoding.
  --&gt; ReplContract.sol:14:19:
   |
14 |         keccak256(address(0));
</code></pre>
<p>This approach raises two questions for me:</p>
<ul>
<li>Why are we relying on interface encodings to satisfy cryptographic properties?</li>
<li>Encoding requires complex recursive/nested data processing, memory expansion,
and making more than a full copy of the data to include headers, is that
significant gas cost strictly necessary?</li>
</ul>
<h3 id="non-goals"><a class="header" href="#non-goals">Non goals</a></h3>
<p>For the purpose of this document we are NOT attempting any specific compatibility
with external systems or standards, etc.</p>
<p>The basic use case is that we are writing contracts that need to convince
themselves that they should authorize some state change.</p>
<p>Often we find ourselves with a lot of state that informs the authorization
verification logic. Too much to store, sign, etc. so first we want to
&quot;hash the data&quot; and just store, compare, sign the hash.</p>
<p>It doesn't really matter in this case what the hashing algorithm is, as long as
it gives us the security guarantees that the contract needs. If the hash is
needed to be known offchain, e.g. so it can be passed back to a future call on
the contract, then the contract can emit the hash into the logs etc.</p>
<p>We are even fine with changing the patterns described in this document over time.
There's no requirement that a hash produced by one contract is compatible with
the hash produced by another. Our goal is that contracts implementing these
patterns can securely accept arbitrary inputs, NOT that the basic approach
ossifies due to unrelated contracts doing different things to each other.</p>
<p><strong>That is to say, there's no &quot;upgradeable contract&quot; support.</strong></p>
<p>Further, while we do want to be able to support &quot;any&quot; data type in our pattern,
we do NOT need to support &quot;every&quot; data type in our implementations. It may be
relatively onerous to implement and maintain the required assembly logic to
safely hash some structure, relative to just slapping an abi encoding on the
problem and walking away. The intention is that this work would only be needed
for maybe 1 or 2 structs within a codebase, because there wouldn't be a large
variety of security sensitive hashing to be done for some given contract/context.</p>
<p>It's also assumed that, because these structs are used on the critical security
path, there would be good reasons to design them for stability and simplicity
already. In this case, the maintainability concerns that always arise when
handling structs in assembly (adding/removing/reordering fields!) are naturally
less of a concern due to their context/usage.</p>
<h3 id="encoding-and-cryptography"><a class="header" href="#encoding-and-cryptography">Encoding and cryptography</a></h3>
<p>An earlier version of the EIP712 spec outlined the difficulty in relying on
encoding formats to provide cryptographic guarantees.</p>
<blockquote>
<p>A good hashing algorithm should satisfy security properties such as
determinism, second pre-image resistance and collision resistance. The
keccak256 function satisfies the above criteria when applied to bytestrings. If
we want to apply it to other sets we first need to map this set to bytestrings.
It is critically important that this encoding function is deterministic and
injective. If it is not deterministic then the hash might differ from the
moment of signing to the moment of verifying, causing the signature to
incorrectly be rejected. If it is not injective then there are two different
elements in our input set that hash to the same value, causing a signature to
be valid for a different unrelated message.</p>
<p>An illustrative example of the above breakage can be found in Ethereum.
Ethereum has two kinds of messages, transactions ùïã and bytestrings ùîπ‚Å∏‚Åø. These
are signed using eth_sendTransaction and eth_sign respectively. Originally the
encoding function encode : ùïã ‚à™ ùîπ‚Å∏‚Åø ‚Üí ùîπ‚Å∏‚Åø was defined as follows:</p>
<ul>
<li>encode(t : ùïã) = RLP_encode(t)</li>
<li>encode(b : ùîπ‚Å∏‚Åø) = b</li>
</ul>
<p>encode(b : ùîπ‚Å∏‚Åø) = &quot;\x19Ethereum Signed Message:\n&quot; ‚Äñ len(b) ‚Äñ b where len(b) is
the ascii-decimal encoding of the number of bytes in b.</p>
<p>This solves the collision between the legs since RLP_encode(t : ùïã) never starts
with \x19. There is still the risk of the new encoding function not being
deterministic or injective. It is instructive to consider those in detail.</p>
<p>As is, the definition above is not deterministic. For a 4-byte string b both
encodings with len(b) = &quot;4&quot; and len(b) = &quot;004&quot; are valid. This can be solved by
further requiring that the decimal encoding of the length has no leading zeros
and len(&quot;&quot;) = &quot;0&quot;.</p>
<p>The above definition is not obviously collision free. Does a bytestring
starting with &quot;\x19Ethereum Signed Message:\n42a‚Ä¶&quot; mean a 42-byte string
starting with a or a 4-byte string starting with 2a?. This was pointed out in
Geth issue #14794 and motivated Trezor to not implement the standard as-is.
Fortunately this does not lead to actual collisions as the total length of the
encoded bytestring provides sufficient information to disambiguate the cases.</p>
<p>Both determinism and injectiveness would be trivially true if len(b) was left
out entirely. The point is, it is difficult to map arbitrary sets to
bytestrings without introducing security issues in the encoding function. Yet
the current design of eth_sign still takes a bytestring as input and expects
implementors to come up with an encoding.</p>
</blockquote>
<p>This is good context that has sadly been removed from current versions of the
EIP.</p>
<p>The key takeaways are:</p>
<ul>
<li>We need something determinstic and injective, which can probably be summarised
in a single word as &quot;unambiguous&quot;</li>
<li>Hashing bytes is secure by default and any encoding scheme's security can only
be less than or equal to the security of the hash of the raw data before it is
encoded</li>
<li>It is difficult to assess the cryptographic qualities of an encoding scheme and
high profile mistakes can be found in the wild, including formal standards</li>
</ul>
<h4 id="collisions-with-abi-encoding"><a class="header" href="#collisions-with-abi-encoding">Collisions with ABI encoding</a></h4>
<p>Perhaps unsurprisingly we can find one of these issues in <code>abi.encodePacked</code> as
this encoding scheme simply concatenates bytes together.</p>
<p>This means that <code>&quot;abc&quot; + &quot;def&quot;</code> and <code>&quot;ab&quot; + &quot;cdef&quot;</code> will pack to the same final
bytestring, <code>&quot;abcdef&quot;</code>.</p>
<p>We can suggest potential workarounds like &quot;only use packed encoding for fixed
length input data&quot;, but it's clear that packed encoding is situationally useful
at best, and dangerous at worst.</p>
<p>The suggested fix is usually to use <code>abi.encode</code>, which adds additional
information to the raw data as part of the encoding. Something like
<code>3&quot;abc&quot; + 3&quot;def&quot;</code> with length prefixes and <code>2&quot;ab&quot; + 4&quot;cdef&quot;</code>, and then additional
head/tail structures that encode the offsets of the dynamic length data in an
overall prefix to the encoded data.</p>
<p>https://docs.soliditylang.org/en/develop/abi-spec.html#formal-specification-of-the-encoding</p>
<p>Importantly, in light of the discussion in EIP712, the lengths are fixed length
themselves, always represented as a <code>uint256</code>, so the full <code>abi.encode</code> encoding
of the underlying data is probably safe.</p>
<p>So <code>abi.encode</code> doesn't have the problems of <code>abi.encodePacked</code> nor early geth
implementations, but is that a strong proof that it doesn't introduce new
problems?</p>
<h4 id="gas-cost-of-encoding"><a class="header" href="#gas-cost-of-encoding">Gas cost of encoding</a></h4>
<p>If <code>abi.encode</code> was an efficient function, we could probably be happy that it has
sufficient adoption and time without exploit to use it. Even if there was some
issue, &quot;nobody ever got fired for using <code>abi.encode</code>&quot;, right?</p>
<p>Doing the same thing as everyone else, and as the security researchers recommend
in audits, is usually a good idea.</p>
<p>The issue here is that <code>abi.encode</code> is not particularly gas efficient. This is a
fundamental issue and not at all the &quot;fault&quot; of Solidity. To encode anything with
any algorithm and not cause the original data to be corrupted/unsafe to use, the
EVM must allocate a new region of memory to house the encoded data. If we allow
for dynamic length data types, the UNAVOIDABLE runtime overhead of ANY
schemaless/uncompressed encoding algorithm is:</p>
<ul>
<li>Calculate the size of memory to allocate for the encoded output by recursively
traversing the input data</li>
<li>Allocate the memory and pay nonlinear gas for expansion costs</li>
<li>Make a complete copy of the input data</li>
<li>Write additional data for the encoding itself, e.g. type/length prefixes,
headers, magic numbers, etc.</li>
</ul>
<p>The Solidity type system can definitely make a lot of this more efficient,
especially the traversal bit, by generating the traversal process at compile time
but it can't hand wave away the need for allocating and copying.</p>
<p><strong>Typically, my experience has shown that if some algorithm <code>f(x)</code> is implemented
in a functionally equivalent way, where one implementation internally encodes <code>x</code>
and another avoids it, the no-encode solution often costs 40-80%+ less gas.</strong>
This saving is of course most noticeable when the algorithm is relatively
efficient, or involves a tight internal loop over encoding, such that the
encoding then starts to dominate the profile. Even in cases where that is not
true, such as comparing the reference SSTORE2 implementation to
<a href="https://github.com/rainprotocol/sol.lib.datacontract/blob/main/src/LibDataContract.sol">LibDataContract</a> we still can see 1k+ gas savings per-write for common usage patterns, with
identical outcomes.</p>
<p>It really just seems to come down to the fact that memory expansion and bulk
copying nested/dynamic is not a cheap thing to do. It's typically not millions of
gas, but it can easily be 1-10k+ gas for what is often unneccessary work.</p>
<p>Note however that <code>keccak256</code> itself is non destructive, it can happily produce
a hash on the stack without modifying or allocating any memory at all. Even in
the case that some data is NOT in memory yet and we want to hash it
(e.g. on the stack), there is a dedicated region of memory from <code>0-0x40</code> called
&quot;scratch space for hashing methods&quot;. We can put any two words in the scratch
space and hash them together without interacting with the allocator at all.</p>
<p>What perhaps is the &quot;fault&quot; of Solidity is that they don't implement <code>keecak256</code>
for any type other than <code>bytes</code> so we are forced to go all the way to Yul and
write assembly the moment we want to do anything other than <code>abi.encode</code>.</p>
<h2 id="solution"><a class="header" href="#solution">Solution</a></h2>
<ul>
<li>Define a pattern to hash any Solidity data structure without allocation and
minimal memory reads/writes, and is generally efficient</li>
<li>Convince ourselves the pattern is unambiguous/secure, being both deterministic
and injective</li>
<li>Provide a reference implementation of the pattern that can be fuzzed against
to show inline implementations of the pattern provide valid outputs</li>
</ul>
<h3 id="the-pattern"><a class="header" href="#the-pattern">The pattern</a></h3>
<p>The memory layout of data in Solidity is very regular across all data types.</p>
<p>https://docs.soliditylang.org/en/v0.8.19/internals/layout_in_memory.html</p>
<p>It is optimised so that the allocator always has the free memory pointer at a
multiple of 32.</p>
<p>Note that the memory layout is completely different to e.g. the storage layout.
Everything discussed here is specific to data in memory and does not generalise
at all.</p>
<p>All non-struct types end up in one of 3 buckets:</p>
<ul>
<li>1 or more 32 byte words, of <code>length</code> defined by the type</li>
<li>A 32 byte <code>length</code> followed by <code>length</code> 32 byte words (most dynamic types)</li>
<li>A 32 byte <code>length</code> followed by <code>length</code> bytes (<code>bytes</code> and <code>string</code> only)</li>
</ul>
<p>Note that in the last case, the allocator will still move the free memory pointer
to a multiple of 32 bytes even if that points past the end of the data structure.</p>
<p>The variables and structs that reference these things are pointers to them, or
even nested pointers in the case of structs. The pointers can be either on the
stack or in memory, depending on context.</p>
<p>Consider the struct</p>
<pre><code class="language-solidity">struct Foo {
    uint256 a;
    address b;
    uint256[] c;
    bytes d;
}
</code></pre>
<p>If we had some <code>foo_</code> such that <code>Foo memory foo_ = Foo(...);</code> then <code>foo_</code> will
be a pointer, either on the stack or in memory, depending on compiler
optimisations.</p>
<p>The thing it points to falls into the first bucket, a 4-word region of memory
defined by its type. This may not be intuitive but all of <code>uint256</code>, <code>address</code>,
<code>uint256[]</code> and <code>bytes</code>, and all other types, are all a full singular word in
the struct.</p>
<p>Any types that are smaller than 1 word are padded with 0's such that they retain
the same <code>uint256</code> equivalent value.</p>
<p>Any types that are larger, or potentially larger than 1 word are pointers to that
data, from the perspective of the struct.</p>
<p>This logic is applied recursively.</p>
<p>This means that structs are NOT dynamic length, regardless of how nested or how
many dynamic types appear in their definition, or the definitions of types within
their fields. For example, a <code>Foo</code> is ALWAYS 4 words, i.e. 0x80 bytes long.</p>
<p>Given the above, we can</p>
<ul>
<li>Define a pattern for hashing each of the 3 possible memory layouts</li>
<li>Explain how to handle pointers across non-contigous regions of memory</li>
<li>Discuss the security of the composition</li>
<li>Provide a guide for implementation, maintenance and quality assurance</li>
</ul>
<h4 id="hashing-contigious-words"><a class="header" href="#hashing-contigious-words">Hashing contigious words</a></h4>
<p>In all cases where the size of the data is a known number of words at compile
time we are free to simply hash the known memory region.</p>
<p>For example, we could hash a <code>foo_</code> as above like so</p>
<pre><code class="language-solidity">assembly (&quot;memory-safe&quot;) {
    let hash_ := keccak256(foo_, add(foo_, 0x80))
}
</code></pre>
<p>Ignore for now that <code>c</code> and <code>d</code> are pointers, as that will be discussed later in
this document.</p>
<p>The basic point is that the code example shows that Yul handles what we need
for known memory regions very naturally.</p>
<p>Other than implementation bugs, there's no potential for</p>
<ul>
<li>Collisions</li>
<li>Including data what we did not intend to in the hash input</li>
<li>Failing to include some part of the struct</li>
</ul>
<p>Because the size of the data never changes, we can just hardcode it per-type.</p>
<h4 id="hashing-dynamic-length-list-of-words"><a class="header" href="#hashing-dynamic-length-list-of-words">Hashing dynamic length list of words</a></h4>
<p>Most dynamic length types in Solidity are a list of 32 byte words. This includes
lists of pointers like <code>Foo[]</code>, single byte values <code>bytes1[]</code>, etc.</p>
<p>The ONLY exceptions to the rule are <code>bytes</code> and <code>string</code> types.</p>
<p>Again, ignoring pointers for now, we can hash any dynamic length word list as</p>
<pre><code class="language-solidity">assembly (&quot;memory-safe&quot;) {
    // Assume bar_ is some dynamic length list of words
    let hash_ := keccak256(
        // Skip the length prefix
        add(bar_, 0x20),
        // Read the length prefix and multiply by 0x20 to know how many _words_
        // to hash
        mul(mload(bar_), 0x20)
    )
}
</code></pre>
<p>Note that here we DO NOT include the length prefix in the bytes that we hash.</p>
<p>This gives us the same behaviour as the case of hashing static length data, but
with lengths known only at runtime.</p>
<p>When it comes to composition we do not want to rely on length prefixes for safety
guarantees, as they are not always available. As EIP712 explained, length
prefixes can introduce ambiguity as easily as they can resolve them as in the
case of packed encoding. Ideally we can show security without the need for any
additional metadata about our words.</p>
<h4 id="hashing-dynamic-length-byte-strings"><a class="header" href="#hashing-dynamic-length-byte-strings">Hashing dynamic length byte strings</a></h4>
<p>The two byte length types <code>bytes</code> and <code>string</code> are the only types in Solidity
that may not have whole-world lengths. Even though the allocator retains a
multiple of 0x20 on the free memory pointer, we MUST respect the true length of
<code>bytes</code> and <code>string</code> in bytes, otherwise we introduce ambiguity.</p>
<p>If we did not respect the length then <code>hex&quot;01&quot;</code> and <code>hex&quot;0100&quot;</code> would hash to
the same value, as they both have 0x20 bytes <em>allocated</em> to them in memory, even
though the first is 1 byte and the second is 2 bytes in <em>length</em>.</p>
<p>The assembly for this is actually simpler than dealing with words as we do not
need to convert between length/bytes. It is the same for <code>string</code> and <code>bytes</code>.</p>
<pre><code class="language-solidity">assembly (&quot;memory-safe&quot;) {
    // Assume baz_ is some bytes/string
    let hash_ := keccak256(
        // Skip the length prefix
        add(baz_, 0x20),
        // Read the length prefix to know how many _bytes_ to hash
        mload(baz_)
    )
}
</code></pre>
<p>Note that pointers never appear in <code>bytes</code> nor <code>string</code>, or if they do, they are
not going to be dereferenced by our hashing logic. This assembly above is all
that is needed to hash <code>bytes</code> and <code>string</code> types.</p>
<h4 id="handling-pointers"><a class="header" href="#handling-pointers">Handling pointers</a></h4>
<p>It would be pointless to hash pointers (no pun intended). A pointer is merely an
offset in memory, which has very little to do with the data on the other side of
it, and is not even deterministic.</p>
<p>We find pointers in Solidity wherever something that is potentially larger than
1 word needs to fit in a single word slot. For example, any time a struct or
dynamic type is an item or field in another struct or dynamic type.</p>
<p>Solidity does not allow mixed type lists so all pointers are at least found in
predictable positions. We always know at compile time whether something is a
pointer or not, either because it's a field at a known offset, or we are dealing
with an individual or list or pointers directly.</p>
<p>To reliably handle pointers without allocations:</p>
<ul>
<li>Compute the hash of all data up to the pointer</li>
<li>Compute the hash of all data referenced by the pointer</li>
<li>Hash these two hashes together</li>
</ul>
<p>Using our <code>Foo</code> struct from above as an example this would look like:</p>
<ul>
<li>Hash the first two words as a contigious memory region of known size as <code>A</code></li>
<li>Hash the dynamic word list <code>foo_.c</code> as <code>B</code></li>
<li>Write <code>A</code> and <code>B</code> to scratch space at <code>0</code> and <code>0x20</code> respectively</li>
<li>Hash the scratch space to produce <code>C</code></li>
<li>Hash the bytes <code>foo_.d</code> as <code>D</code></li>
<li>Write <code>C</code> and <code>D</code> to scratch space as above</li>
<li>Hash the scratch space to produce <code>E</code>, which is our final hash of <code>Foo</code></li>
</ul>
<p>As assembly it would look like</p>
<pre><code class="language-solidity">assembly (&quot;memory-safe&quot;) {
    // hash foo_.a and foo_.b together to produce hash A
    // store A in scratch
    mstore(0, keccak256(foo_, add(foo_, 0x40)))

    // Follow the pointer to hash foo_.c into B
    let deref_ := mload(add(foo_, 0x60))
    // Store B in scratch
    mstore(0x20, keccak256(add(deref_, 0x20), mul(mload(deref_), 0x20)))

    // Hash A and B to produce C which can be stored direct in scratch
    mstore(0, keccak256(0, 0x40))

    // Follow the pointer to hash foo_.d
    deref_ := mload(add(foo_, 0x80))
    // Store D in scratch
    mstore(0x20, keccak256(add(deref_, 0x20), mload(deref_)))

    // Write C and D to scratch to produce the final hash E
    let E := keccak256(0, 0x40)
}
</code></pre>
<p>If we had a list of pointers, such as a <code>Foo[]</code> then this would be modelled as
a simple fold/reduce style accumulator where each item is hashed as above
individually then hashed into the accumulator. I.e. Hash <code>foos_[0]</code> to hash A,
then hash <code>foos_[1]</code> to hash B, then write both to scratch and hash to produce C,
then hash <code>foos_[2]</code> to hash D, and hash C and D to produce E, etc.</p>
<p>This process of iterating and accumulating a hash incrementally seems to be about
40% cheaper in gas terms than ABI encoding then hashing, based on some simple
testing with Foundry.</p>
<h5 id="nil-hash-prefix"><a class="header" href="#nil-hash-prefix">Nil hash prefix</a></h5>
<p>If we are handling a pointer and have no hash, e.g. we're directly hashing an
array of pointers, we start with the hash of nil bytes, i.e. <code>keccak256(0, 0)</code>.</p>
<p>If the array is 0 length then the hash will be the nil hash, regardless of the
type behind the pointers.</p>
<h4 id="security-of-composition"><a class="header" href="#security-of-composition">Security of composition</a></h4>
<p>Assume that we're comfortable with concepts like blockchains and merkle trees,
that rely on hashes of hashes to iteratively build a single hash out of a system
of hashes.</p>
<p>We need to convince ourselves that the hashing process above is unambiguous for
all permutations.</p>
<p>This relies on us accepting that <code>hash(hash(a) + hash(b))</code> will not collide with
<code>hash(hash(c) + hash(d))</code> for all values of <code>a</code>, <code>b</code>, <code>c</code>, <code>d</code> except the trivial
case where <code>a</code> = <code>c</code> and <code>b</code> = <code>d</code>.</p>
<p>As long as <code>hash(x)</code> and <code>hash(x) + hash(y)</code> don't produce collisions then this
is true. This guarantee seems to come down to the strength of <code>keccak256</code> itself.</p>
<p>As <code>keccak256</code> always produces hashes exactly 32 bytes long for all inputs, we avoid
all the issues seen with both including and excluding length prefixes, such as
those seen in <code>abi.encodePacked</code>.</p>
<p>I'm not sure this constitutes a formal mathematical proof, but I'm not sure if
one exists for <code>abi.encode</code> either :)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="libhashnoalloc"><a class="header" href="#libhashnoalloc">LibHashNoAlloc</a></h1>
<p><a href="https://github.com/rainprotocol/rain.lib.hash/blob/59c3ded1c19740d4551facfb857c9e8ca88a19df/src/LibHashNoAlloc.sol">Git Source</a></p>
<p>When producing hashes of just about anything that isn't already bytes
the common suggestions look something like <code>keccak256(abi.encode(...))</code> or
<code>keccak256(abi.encodePacked(...))</code> with the main differentiation being
whether dynamic data types are being hashed. If they are then there is a hash
collision risk in the packed case as <code>&quot;abc&quot; + &quot;def&quot;</code> and <code>&quot;ab&quot; + &quot;cdef&quot;</code> will
pack and therefore hash to the same values, the suggested fix commonly being
to use abi.encode, which includes the lengths disambiguating dynamic data.
Something like <code>3&quot;abc&quot; + 3&quot;def&quot;</code> with the length prefixes won't collide with
<code>2&quot;ab&quot; + 4&quot;cdef&quot;</code> but note that ABI provides neither a strong guarantee to
be collision resitant on inputs (as far as I know, it's a coincidence that
this works), nor an efficient solution.</p>
<ul>
<li>Abi encoding is a complex algorithm that is easily 1k+ gas for simple
structs with just one or two dynamic typed fields.</li>
<li>Abi encoding requires allocating and copying all the data plus a header to
a new region of memory, which gives it non-linearly increasing costs due to
memory expansion.</li>
<li>Abi encoding can't easily be reproduced offchain without specialised tools,
it's not simply a matter of length prefixing some byte string and hashing
with keccak256, the heads and tails all need to be produced recursively
https://docs.soliditylang.org/en/develop/abi-spec.html#formal-specification-of-the-encoding
Consider that <code>hash(hash(&quot;abc&quot;) + hash(&quot;def&quot;))</code> won't collide with
<code>hash(hash(&quot;ab&quot;) + hash(&quot;cdef&quot;))</code>. It should be easier to convince ourselves
this is true for all possible pairs of byte strings than it is to convince
ourselves that the ABI serialization is never ambigious. Inductively we can
scale this to all possible data structures that are ordered compositions of
byte strings. Even better, the native behaviour of <code>keccak256</code> in the EVM
requires no additional allocation of memory. Worst case scenario is that we
want to hash several hashes together like <code>hash(hash0, hash1, ...)</code>, in which
case we can write the words after the free memory pointer, hash them, but
leave the pointer. This way we pay for memory expansion but can re-use that
region of memory for subsequent logic, which may effectively make the
expansion free as we would have needed to pay for it anyway. Given that hash
checks often occur early in real world logic due to
checks-effects-interactions, this is not an unreasonable assumption to call
this kind of expansion &quot;no alloc&quot;.
One problem is that the gas saving for trivial abi encoding,
e.g. ~1-3 uint256 values, can be lost by the overhead of jumps and stack
manipulation due to function calls.</li>
</ul>
<pre><code>struct Foo {
uint256 a;
address b;
uint32 c;
}
</code></pre>
<p>The simplest way to hash <code>Foo</code> is to just hash it (crazy, i know!).</p>
<pre><code>assembly (&quot;memory-safe&quot;) {
hash_ := keccak256(foo_, 0x60)
}
</code></pre>
<p>Every struct field is 0x20 bytes in memory so 3 fields = 0x60 bytes to hash
always, with the exception of dynamic types. This costs about 70 gas vs.
about 350 gas for an abi encoding based approach.</p>
<h2 id="functions"><a class="header" href="#functions">Functions</a></h2>
<h3 id="hashbytes"><a class="header" href="#hashbytes">hashBytes</a></h3>
<pre><code class="language-solidity">function hashBytes(bytes memory data_) internal pure returns (bytes32 hash_);
</code></pre>
<h3 id="hashwords"><a class="header" href="#hashwords">hashWords</a></h3>
<pre><code class="language-solidity">function hashWords(bytes32[] memory words_) internal pure returns (bytes32 hash_);
</code></pre>
<h3 id="hashwords-1"><a class="header" href="#hashwords-1">hashWords</a></h3>
<pre><code class="language-solidity">function hashWords(uint256[] memory words_) internal pure returns (bytes32 hash_);
</code></pre>
<h3 id="combinehashes"><a class="header" href="#combinehashes">combineHashes</a></h3>
<pre><code class="language-solidity">function combineHashes(bytes32 a_, bytes32 b_) internal pure returns (bytes32 hash_);
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="constants"><a class="header" href="#constants">Constants</a></h1>
<p><a href="https://github.com/rainprotocol/rain.lib.hash/blob/59c3ded1c19740d4551facfb857c9e8ca88a19df/src/LibHashNoAlloc.sol">Git Source</a></p>
<h3 id="hash_nil"><a class="header" href="#hash_nil">HASH_NIL</a></h3>
<pre><code class="language-solidity">bytes32 constant HASH_NIL = 0xc5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470;
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="solidity.min.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
